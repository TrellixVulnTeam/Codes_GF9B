{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \n",
    "    sub_paths = os.listdir(path)\n",
    "\n",
    "    img_data = []\n",
    "    label_data = []\n",
    "    \n",
    "    c = 0\n",
    "    \n",
    "    for sub_path in sub_paths:\n",
    "        \n",
    "        img_paths = os.listdir(path + sub_path)\n",
    "        \n",
    "        for img_path in img_paths:\n",
    "            \n",
    "            img = cv2.imread(path + sub_path + '\\\\' + img_path , 0)\n",
    "\n",
    "            label = int(sub_path)\n",
    "            \n",
    "            img_data.append(img)\n",
    "            label_data.append(label)\n",
    "            \n",
    "            c = c + 1\n",
    "            \n",
    "        print (sub_path)\n",
    "        \n",
    "    img_data = np.expand_dims(np.array(img_data),-1) #converting  to a numpy array\n",
    "    #label_data = tf.one_hot(label_data, 10).eval(session = sess) # one_hot representation\n",
    "    label_data = to_one_hot(label_data, 10)\n",
    "    \n",
    "    img_data, label_data = shuffle(img_data, label_data, random_state=0)\n",
    "    return img_data, label_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(label_data, num_class):\n",
    "    num_sample = np.shape(label_data)[0]\n",
    "    temp = np.zeros([num_sample, num_class])\n",
    "    temp[np.arange(num_sample),label_data] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Network(Input): #input : [Batch_size, 32, 32, 1]\n",
    "    with tf.name_scope(\"Network\"):\n",
    "        conv1 = tf.layers.conv2d(Input, filters = 64, kernel_size = 3, strides = 1, activation = tf.nn.relu, name = 'conv1')\n",
    "        conv2 = tf.layers.conv2d(conv1, filters = 64, kernel_size = 3, strides = 1, activation = tf.nn.relu, name = 'conv2')\n",
    "        pool1 = tf.layers.max_pooling2d(conv2, pool_size = 2, strides = 2, name = 'pool1')\n",
    "\n",
    "        conv3 = tf.layers.conv2d(pool1, filters = 256, kernel_size = 3, strides = 1, activation = tf.nn.relu, name = 'conv3')\n",
    "        conv4 = tf.layers.conv2d(conv3, filters = 256, kernel_size = 3, strides = 1, activation = tf.nn.relu, name = 'conv4')\n",
    "        pool2 = tf.layers.max_pooling2d(conv4, pool_size = 2, strides = 2, name = 'pool2')\n",
    "\n",
    "        conv5 = tf.layers.conv2d(pool2, filters = 512, kernel_size = 3, strides = 1, activation = tf.nn.relu, name = 'conv5')\n",
    "\n",
    "        flat = tf.contrib.layers.flatten(conv5)\n",
    "        fc1 = tf.layers.dense(flat, units = 1024, activation = tf.nn.relu, name = 'fc1')\n",
    "        fc2 = tf.layers.dense(fc1, units = 10, activation = None, name = 'fc2')\n",
    "    \n",
    "    return fc2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_function(logit, Label):\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logit, labels = Label))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Accuracy_Evaluate(prediction, Label):\n",
    "    # Evaluate model\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    return correct_pred, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(train_data, train_label, no_of_epochs = 150000, batchsize = 32):\n",
    "    \n",
    "    \n",
    "    Input = tf.placeholder(dtype = tf.float32, shape = [None, 28, 28, 1])\n",
    "    Label = tf.placeholder(dtype = tf.float32, shape = [None, 10])\n",
    "    \n",
    "    logit = Network(Input)\n",
    "    \n",
    "    prediction = tf.nn.softmax(logit)\n",
    "    \n",
    "    loss = loss_function(logit, Label)\n",
    "    \n",
    "    correct_pred, accuracy = Accuracy_Evaluate(prediction, Label)\n",
    "    \n",
    "    \n",
    "    optimiz = tf.train.GradientDescentOptimizer(learning_rate = 0.001).minimize(loss)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    " \n",
    "    \n",
    "    tf.summary.scalar('Loss_Value',loss)\n",
    "    tf.summary.scalar('Accuracy',accuracy)\n",
    "    \n",
    "    print('Stteing up summary op...')\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    print('Setting Up Saver...')\n",
    "    summary_writer = tf.summary.FileWriter('./log_dir/', sess.graph)\n",
    "    \n",
    "    itr = 0\n",
    "    for epoch in range(no_of_epochs):\n",
    "        \n",
    "        index = np.random.permutation(np.shape(train_data)[0])\n",
    "        train_data = train_data[index, :, :, :]\n",
    "        train_label = train_label[index, :]\n",
    "        \n",
    "        for idx in range(train_data.shape[0]//batchsize): \n",
    "            \n",
    "            batchx = train_data[idx*batchsize : (idx + 1)*batchsize , :, :, :]\n",
    "            batchy = train_label[idx*batchsize : (idx + 1)*batchsize, :]\n",
    "            \n",
    "            feed_dict = {Input : batchx , Label : batchy}\n",
    "            \n",
    "            _, train_loss, train_accuracy, summary_str = sess.run([optimiz, loss, accuracy, summary_op] , feed_dict )\n",
    "            summary_writer.add_summary(summary_str, itr)\n",
    "            itr = itr + 1\n",
    "            \n",
    "            if idx%10 == 0:\n",
    "                \n",
    "                print ('epoch : '+str(epoch)+' step : '+str(idx) + ' train_loss : '+str(train_loss) +\n",
    "                        ' train_accuracy : '+str(train_accuracy) \n",
    "            \n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "global sess\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "sess = tf.Session(config = config)\n",
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label = load_data('C:\\\\WinPython-64bit-3.5.4.0Qt5\\\\notebooks\\\\trainingSet.tar\\\\trainingSet\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyKn/BzTSGSEz/yD/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b31498a4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(train_data[110,:,:,0])\n",
    "plt.show()\n",
    "print(np.argmax(train_label[110]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stteing up summary op...\n",
      "Setting Up Saver...\n",
      "epoch : 0 step : 0 train_loss : 2.43485 train_accuracy : 0.15625\n",
      "epoch : 0 step : 10 train_loss : 0.331961 train_accuracy : 0.3125\n",
      "epoch : 0 step : 20 train_loss : 0.275277 train_accuracy : 0.25\n",
      "epoch : 0 step : 30 train_loss : 0.220457 train_accuracy : 0.5625\n",
      "epoch : 0 step : 40 train_loss : 0.20844 train_accuracy : 0.71875\n",
      "epoch : 0 step : 50 train_loss : 0.153882 train_accuracy : 0.8125\n",
      "epoch : 0 step : 60 train_loss : 0.176033 train_accuracy : 0.65625\n",
      "epoch : 0 step : 70 train_loss : 0.16939 train_accuracy : 0.65625\n",
      "epoch : 0 step : 80 train_loss : 0.153948 train_accuracy : 0.75\n",
      "epoch : 0 step : 90 train_loss : 0.120888 train_accuracy : 0.78125\n",
      "epoch : 0 step : 100 train_loss : 0.105372 train_accuracy : 0.84375\n",
      "epoch : 0 step : 110 train_loss : 0.108493 train_accuracy : 0.875\n",
      "epoch : 0 step : 120 train_loss : 0.142021 train_accuracy : 0.71875\n",
      "epoch : 0 step : 130 train_loss : 0.098624 train_accuracy : 0.8125\n",
      "epoch : 0 step : 140 train_loss : 0.142045 train_accuracy : 0.8125\n",
      "epoch : 0 step : 150 train_loss : 0.10732 train_accuracy : 0.8125\n",
      "epoch : 0 step : 160 train_loss : 0.140445 train_accuracy : 0.78125\n",
      "epoch : 0 step : 170 train_loss : 0.0938756 train_accuracy : 0.90625\n",
      "epoch : 0 step : 180 train_loss : 0.0697226 train_accuracy : 0.90625\n",
      "epoch : 0 step : 190 train_loss : 0.0599463 train_accuracy : 1.0\n",
      "epoch : 0 step : 200 train_loss : 0.105865 train_accuracy : 0.6875\n",
      "epoch : 0 step : 210 train_loss : 0.0879404 train_accuracy : 0.8125\n",
      "epoch : 0 step : 220 train_loss : 0.0763751 train_accuracy : 0.90625\n",
      "epoch : 0 step : 230 train_loss : 0.10462 train_accuracy : 0.8125\n",
      "epoch : 0 step : 240 train_loss : 0.114651 train_accuracy : 0.90625\n",
      "epoch : 0 step : 250 train_loss : 0.0734449 train_accuracy : 0.9375\n",
      "epoch : 0 step : 260 train_loss : 0.0720439 train_accuracy : 0.9375\n",
      "epoch : 0 step : 270 train_loss : 0.0568161 train_accuracy : 0.96875\n",
      "epoch : 0 step : 280 train_loss : 0.0753841 train_accuracy : 0.9375\n",
      "epoch : 0 step : 290 train_loss : 0.0610816 train_accuracy : 0.9375\n"
     ]
    }
   ],
   "source": [
    "main(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resource\n",
    "# https://stackoverflow.com/questions/29831489/numpy-1-hot-array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
